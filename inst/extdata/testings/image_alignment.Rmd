---
title: "Image Alignment in R"
editor_options: 
  chunk_output_type: inline
---

# Setup

```{r setup}
if(!requireNamespace("imager", quietly = T)) install.packages("imager")

library(imager)
library(rcell2.examples) # devtools::load_all()
library(tidyverse)
```

# Tests with imager

- https://cran.r-project.org/web/packages/imager/vignettes/gettingstarted.html
- http://dahtah.github.io/imager/
  - https://dahtah.github.io/imager/imager.html
  - https://dahtah.github.io/imager/morphology.html
  - https://github.com/ShotaOchi/imagerExtra
  - https://cran.r-project.org/web/packages/imagerExtra/vignettes/gettingstarted.html

## Methods

Functions defined in this package:

```{r}
?crop_cimg_around_xy
?fftshift
?cross_correlation
?img_alignment_offset
```

## Data

```{r}
data.dir <-
  "~/Projects/PhD/gitlabs_acl/rtcc/kar4/2024-08-22-RtCC-Ali-5-cepas-y-CFP/data/2024-08-22-RtCC-Ali-5-cepas-y-CFP/renamed/"
```


```{r}
# Load two images
frame1 <- file.path(data.dir, "BF_Position01_time02.tif") |> load.image()
frame2 <- file.path(data.dir, "BF_Position01_time04.tif") |> load.image()
```


```{r}
x <- 495
y <- 530
w <- 51

# Crop frame1.
img1 <- frame1 |> crop_cimg_around_xy(x, y, w) #|> plot()

# Crop frame2.
img2 <- frame2 |> crop_cimg_around_xy(x, y, w) #|> plot()

# Display the cropped images.
par(mfrow = c(1, 2))
plot(img1, main="Reference")
plot(img2, main="Query")
```

## Test

```{r}
cross_correlation(img1, img2) |> plot()
```


```{r}
# Calculate the offset through cross-correlation.
xy_offsets <- img_alignment_offset(img1, img2)

# Crop from the original image.
aligned_image <- crop_cimg_around_xy(frame2, x=x-xy_offsets[1], y=y-xy_offsets[2], w=w)

# Align the cropped image.
# aligned_image <- imager::imshift(img2, delta_x = xy_offsets[1], delta_y = xy_offsets[2])
```

```{r}
# Visualize the results
par(mfrow = c(2, 2))
cross_correlation(img1, img2) |> plot()
abline(h=xy_offsets["max_cor_y"], col="red")
abline(v=xy_offsets["max_cor_x"], col="red")
plot(img1, main = "Image 1")
plot(img2, main = "Image 2")
plot(aligned_image, main = "Image 2 (Aligned)")
```

# Test with EBIMage

No existe "computeTranslation", flasheó ChatGPT.

```{r}
# library(EBImage)
# 
# # Load images
# 
# # Load two images
# img1 <- file.path(data.dir, "BF_Position01_time02.tif") |> readImage()
# img2 <- file.path(data.dir, "BF_Position01_time04.tif") |> readImage()
# 
# # Compute translation using normalized cross-correlation
# translation <- computeTranslation(img1, img2)
# 
# # Apply the transformation
# aligned_img2 <- translate(img2, translation)
# 
# # Display the result
# display(combine(img1, aligned_img2))
```

# Tagging cells

The "multi-point" tool in ImageJ can be used to mark cells with different "counters",
by simply clicking on them in the image.

These marks can be exported and mapped back to `ucid`s in R, and then
used for filtering and analysis.

Steps:

1. Open the images in a Hyperstack, as described in the [Preview images using ImageJ] section.
2. Use the multi-point tool to mark individual cells with one or more "counters", as required by your experiment.
3. After tagging the cells, generate the measurements (press `Ctrl+M`) and save
   them to a `.csv` file (press `Ctrl+S`, or `File -> Save`).
  - It is critical that you check that the values of the "Ch" (channel), 
    "Slice", and "Frame" ImageJ measurements map correctly to `t.frame`s,
    `pos`, and `ch` in Cell-IDs output.
  - Note that ImageJ's time indexes begin at 1, but Cell-ID's 
    begin at 0. This may need to be adjusted later.

Detailed instructions on how to import these points and map them to cells 
identified by Cell-ID, can be found in the [Cell-tagging using ImageJ] section
of this notebook.

## Notas sobre el tagueo

1. Taguear celulas CFP en una cepa (6122, delta pho85).
  - Dio razonable. La mejor dosis para cuantificar entre cepas es 1 nM, porque se nota el efecto, y todas las cepas van a estar más a la derecha.
2. Taguear celulas CFP en la dosis de 1 nM, para comprobar que la dosis de feromona efectiva fue homogénea entre wells de la misma columna.
3. Taguear cepas del exp. a 1 nM.
  - *Todas* las células CFP en el well F6 (pos 37 y 38) terminaron **muertas**. No vi esto en el resto de las posiciones, pero tampoco lo busqué.
  - Se ve que las células de esas posiciones tienen una dinamica de switching diferente a la de las demas.

## Load tags

### Tag metadata

```{r}
counter_set1 <- bind_rows(
  data.frame(cell="cfp", Counter = c(0,1,4), tag = c("cell", "bud", "dead")),
  data.frame(cell="exp", Counter = 2:3, tag = c("cell", "bud"))
)

# counter_set1
```

### Control CFP Strain

```{r}
tags_dir <- 
  "~/Projects/PhD/gitlabs_acl/rtcc/kar4/2024-08-22-RtCC-Ali-5-cepas-y-CFP/data/tags"

tags_raw_cfp <- dir(tags_dir, pattern = "*.csv", full.names = T) |> 
  lapply(read.csv) |> 
  bind_rows() |>
  # filter(Counter %in% 1) |>
  left_join(counter_set1,by = join_by(Counter))

# tags_raw_cfp |> 
#   ggplot(aes(X, Y, color = as.factor(Counter))) +
#   geom_point() + 
#   facet_wrap(~Slice) +
#   theme_minimal() + 
#   scale_y_reverse()
```

```{r}
tags_cfp <- tags_raw_cfp |> 
  dplyr::rename(
    pos = Slice,
    t.frame = Frame
  ) |> 
  select(pos, t.frame, cell, tag, X, Y)

# tags_cfp
```

### Experiment Strains

```{r}
tags_raw_exp <- file.path(tags_dir, "exp/") |> dir(pattern = "*.csv", full.names = T) |> 
  lapply(read.csv) |> 
  bind_rows() |>
  filter(Counter %in% 2:3) |>
  left_join(counter_set1,by = join_by(Counter))

# tags_raw_exp |> 
#   ggplot(aes(X, Y, color = as.factor(Counter))) +
#   geom_point() + 
#   facet_wrap(~Slice) +
#   theme_minimal() + 
#   scale_y_reverse()
```


```{r}
tags_exp <- tags_raw_exp |> 
  dplyr::rename(
    pos = Slice,
    t.frame = Frame
  ) |> 
  select(pos, t.frame, cell, tag, X, Y)

# tags_exp
```

### Combine tags

```{r}
all_buds <- bind_rows(tags_cfp,tags_exp) |> 
  filter(tag == "bud")

all_buds
```


# Inspect cells

## Get image paths

```{r}
images <- rcell2.cellid::arguments(data.dir) |> 
  rcell2.cellid::arguments_to_images() |> 
  suppressWarnings()
# images$t.frame |> range()
```

## Generate cdata

```{r}
cdata <- all_buds |> 
  filter(t.frame > 3) |> 
  # mutate(t.frame = min(t.frame + 1, 65)) |> 
  dplyr::rename(xpos=X, ypos=Y) |> 
  mutate(ucid=1:n())
```

## Preview cells

```{r}
# rcell2.magick::magickCell(cdata, images, annotation_params = NULL,
#                           ch = "TFP", normalize_images = T, boxSize = 40, cell_resize = 100) |> 
#   rcell2.magick::magickForKnitr()
```

## Reframe cdata

Re-frame `cdata` to obtain rows for all frames for cell strips:

```{r}
# Transform each group to an arbitrary number of rows
cdata_adj <- cdata |> group_by(pos, ucid) |> 
  # Expand frames around the bud, from the beginning of the experiment.
  reframe(t.frame = 1:(t.frame+1)) |> 
  # Keep only valid frames that exist.
  semi_join(images) |> 
  # Keep only frames after the first, which has a focus shift.
  filter(t.frame > 1) |> 
  # Keep only sequences of sufficient length.
  group_by(ucid) |> 
  filter(n() >= 3) |> 
  # Reinsert the data.
  left_join(
    cdata |> rename(t.bud = t.frame)
  ) |> 
  # Remove cells with no frame after the bud.
  filter(t.bud < max(images$t.frame))

# cdata_adj |> 
#   ggplot() + geom_tile(aes(t.frame, ucid))
```

Check images:

```{r}
# cdata_adj |> 
#   rcell2.magick::cellStrips(images, n_ucids = 5, ch = "TFP",
#                             annotation_params = NULL,
#                             normalize_images = T, boxSize = 40, cell_resize = 100
#                             ) |> 
#   magick::image_join() |> 
#   magick::image_append(stack = T) |> 
#   rcell2.magick::magickForKnitr()
```

# Cell alignment

## Align two images

Sample:

```{r}
d_list <- cdata_adj |> split(~ucid)
# d <- d_list |> sample(1) |> first()
d <- d_list[[398]]

t.bud <- d$t.bud[1]

xy <- d |> filter(t.bud == t.frame) |> with(c(xpos, ypos))

img_paths <- images |> semi_join(d) |> 
  filter(channel == "TFP")
```

Process:

```{r}
# Set reference frame.
t.start <- t.bud
# Get query frame.
t.next <- d |> 
  filter(t.frame != t.start) |> 
  filter(t.frame == t.frame[ which.min(abs(t.frame - t.start)) ]) |> 
  with(t.frame)
```

```{r}
t.start <- 40
t.next <- 32
```

```{r}
# Get image paths.
path1 <- img_paths |> filter(t.frame == t.start) |> with(file)
path2 <- img_paths |> filter(t.frame == t.next) |> with(file)

# Load two images
frame1 <- load.image(path1)
frame2 <- load.image(path2)
```

Some unexpected stuff:

- Amazingly enough, 50 is the only window size that does not "drift" in X and Y by 1.
- I also have no idea why setting the widow size to odd numbers messes up the correlogram.

```{r}
# Set crop size, to not 50, and not odd.
w <- 52
# Set sigma.
s <- NULL
# Set blur sigma.
s2 <- NULL
```

```{r}
# Crop frame1.
img1 <- frame1 |> crop_cimg_around_xy(xy[1], xy[2], w)
# Crop frame2.
img2 <- frame2 |> crop_cimg_around_xy(xy[1], xy[2], w)

# Display the cropped images.
plot(img1, main="Reference")
abline(h=(w+1)/2, col="red")
abline(v=(w+1)/2, col="red")
plot(img2, main="Query")
abline(h=(w+1)/2, col="red")
abline(v=(w+1)/2, col="red")
```

Try smoothing the correlation signal a bit.

```{r}
par(mfrow = c(1, 3))

# Compute cross-correlation
cross_corr <- cross_correlation(img1, img2)
# Display the result
cross_corr |> as.cimg() |> plot(main = "Cross-correlation")

# Display blurred version.
cross_corr |> imager::isoblur(sigma=0.75) |> plot(main = "Iso-blur")

# Gaussian weights.
apply_gaussian_weighting(cross_corr[,,1,1], 250) |> as.cimg() |> plot(main = "Gaussian weighing")
```

```{r}
# Calculate the offset through cross-correlation.
xy_offsets <- img_alignment_offset(img1, img2, s=s, s2 = s2)

xy_offsets[c("offset_x", "offset_y")] <- xy_offsets[c("offset_x", "offset_y")] - 1

xy_offsets[c("offset_x", "offset_y")]
```

```{r}
# Crop from the original image.
aligned_image <- crop_cimg_around_xy(frame2, x=xy[1]-xy_offsets[1], y=xy[2]-xy_offsets[2], w=w)
```

```{r}
# Visualize the results
# par(mfrow = c(2, 2))
cross_correlation(img1, img2) |> plot()
abline(h=(w+1)/2, col="blue")
abline(v=(w+1)/2, col="blue")
abline(h=xy_offsets["max_cor_y"], col="red")
abline(v=xy_offsets["max_cor_x"], col="red")
plot(img1, main = "Image 1")
abline(h=(w+1)/2, col="red")
abline(v=(w+1)/2, col="red")
plot(img2, main = "Image 2")
abline(h=(w+1)/2, col="red")
abline(v=(w+1)/2, col="red")
plot(aligned_image, main = "Image 2 (Aligned)")
abline(h=(w+1)/2, col="red")
abline(v=(w+1)/2, col="red")
```

Note that pixel coordinates are not centered on the pixel in the plot below.

```{r}
m <- cross_correlation(img1, img2)

# m <- m |>
#   imager::isoblur(sigma=s2) |> 
#   as.matrix() |> 
#   apply_gaussian_weighting(s=s)

m_df <- m |> as.matrix() |> 
  t() |> 
  utiles::matrix_to_df() |> 
  arrange(-pix_value)

m_df_max <- m_df |> filter(pix_value == max(pix_value))

m_df |> 
  ggplot(aes(x,y)) +
  geom_tile(aes(fill=pix_value)) +
  geom_tile(fill="yellow", data=m_df_max) +
  geom_hline(yintercept=xy_offsets["max_cor_y"], alpha = .5, color="red") +
  geom_vline(xintercept=xy_offsets["max_cor_x"], alpha = .5, color="red") +
  geom_hline(yintercept=w/2, alpha = .5, linetype=2) +
  geom_vline(xintercept=w/2, alpha = .5, linetype=2) +
  coord_equal() + scale_y_reverse() + 
  ggtitle(paste("Max correlation at:", unlist(m_df_max)[1], unlist(m_df_max)[2], "(yellow)"), 
          paste("Final offsets at:", xy_offsets["max_cor_x"], xy_offsets["max_cor_y"], "(red)")) +
  theme_minimal()
```

## Methods

```{r}
?adjust_offset
?propagate_offsets
```

## Process a cell

Sample:

```{r}
d_list <- cdata_adj |> split(~ucid)

d <- d_list[[398]]
t.bud <- d$t.bud[1]

r <- 2:16
r <- 2:60
r <- 2:6
d <- d_list[[398]] |> 
  mutate(ypos = ypos + 30) |>
  filter(t.frame %in% r)
t.bud <- max(r)  # Reverse

xy <- d |>
  # filter(t.frame == 2) |> # Reverse
  filter(t.frame == max(r)) |> # Reverse
  with(c(xpos, ypos))

img_paths <- images |> 
  semi_join(d, by = join_by(pos, t.frame)) |> 
  filter(channel == "TFP") |> 
  arrange(t.frame)

pics <- d |> 
  rcell2.magick::magickCell(images, normalize_images = T, return_single_imgs = T, annotation_params = NULL,
                            n.cells=nrow(d), 
                            highlight_frames=t.bud,
                            ch = "TFP", boxSize=50) |> 
  rcell2.magick::square_tile(nRow = 3) |> 
  rcell2.magick::magickForKnitr()
```

Test:

```{r}
img_offsets <- img_paths |> 
  arrange(-t.frame) |> # Reverse.
  
  # Align.
  propagate_offsets(t.bud = t.bud, xy = xy, verbose = F) |> 
  
  # Compute cumulative offset.  
  mutate(x_offset_sum = cumsum(x_offset),
         y_offset_sum = cumsum(y_offset)) |> 
  select(pos, t.frame, 
         x_offset, y_offset, 
         x_offset_sum, y_offset_sum, t.ref)

# img_offsets
```

### BUG: exchanged offsets

I need to exchange the X and Y offset sums for alignment to work (or at least display) properly.

I have reviewed this extensively and haven't found the issue. whatever works...

```{r}
d_xy <- d |> 
  left_join(img_offsets) 

pics <- d_xy |> 
  
  # BUG HERE !!!!!
  mutate(xpos = xpos - y_offset_sum) |> # BUG HERE !!!!!
  mutate(ypos = ypos - x_offset_sum) |> # BUG HERE !!!!! 
  # BUG HERE !!!!!
  
  rcell2.magick::magickCell(images, normalize_images = T, annotation_params = NULL,
                            return_single_imgs = T,
                            n.cells=nrow(d), 
                            highlight_frames=t.bud,
                            ch = "TFP", boxSize=50)

# Preview.
pics |> 
  rcell2.magick::square_tile(nRow = 2) |>
  # magick::image_append() |>
  rcell2.magick::magickForKnitr()
```

```{r}
d_xy_img <- d_xy |>  
  select(pos, t.frame, xpos, ypos) |> 
  left_join(img_paths) |> 
  arrange(t.frame) |> 
  split(~t.frame) |> 
  lapply(function(d_corr){
    img <- load.image(d_corr$file)
    crop_cimg_around_xy(img, x = d_corr$xpos, y = d_corr$ypos, w = w)
  })

# Create a 2D tile with configurable rows and columns
tile <- create_image_tile(d_xy_img, n_rows = 5, aspect_ratio = 1)
plot(tile)
```


```{r}
d_xy_img <- d_xy |>  
  mutate(xpos = xpos - y_offset_sum) |>
  mutate(ypos = ypos - x_offset_sum) |> 
  select(pos, t.frame, xpos, ypos) |> 
  left_join(img_paths) |> 
  arrange(t.frame) |> 
  split(~t.frame) |> 
  lapply(function(d_corr){
    img <- load.image(d_corr$file)
    crop_cimg_around_xy(img, x = d_corr$xpos, y = d_corr$ypos, w = w)
  })

# Create a 2D tile with configurable rows and columns
tile <- create_image_tile(d_xy_img, n_rows = 5, aspect_ratio = 1)
plot(tile)
```

### Full time-course test

```{r}
d_list <- cdata_adj |> split(~ucid)

d <- d_list[[398]]

t.bud <- d$t.bud[1]

xy <- d |>
  filter(t.frame == t.bud) |>
  with(c(xpos, ypos))

img_paths <- images |> 
  semi_join(d, by = join_by(pos, t.frame)) |> 
  filter(channel == "TFP") |> 
  arrange(t.frame)
```

Calculate offsets:

```{r}
w <- 50
# s <- 250
# s2 <- 0.75

# w <- 25
s <- NULL
s2 <- NULL

off_drift_x <- 0 # 1
off_drift_y <- 0 # 1.5
```

```{r}
# After budding.
img_paths_post <- img_paths |> 
  filter(t.frame >= t.bud) |> 
  propagate_offsets(t.bud, xy, w, s, s2, xy_adj=F) |> 
  mutate(x_offset_sum = cumsum(x_offset-off_drift_x),
         y_offset_sum = cumsum(y_offset-off_drift_y))

# Before budding.
img_paths_pre <- img_paths |> 
  filter(t.frame <= t.bud) |> 
  arrange(-t.frame) |> 
  propagate_offsets(t.bud, xy, w, s, s2, xy_adj=F)|> 
  mutate(x_offset_sum = cumsum(x_offset-off_drift_x),
         y_offset_sum = cumsum(y_offset-off_drift_y))

# Join results.
img_offsets <- bind_rows(img_paths_pre, 
                         img_paths_post[-1,]) |> 
  arrange(t.frame) |> 
  select(pos, t.frame, 
         x_offset, y_offset, 
         x_offset_sum, y_offset_sum, t.ref)
# img_offsets
```

Mitigate "the BUG" here:

```{r}
# Generate images.
pics <- d |> 
  # left_join(img_paths_pre) |> filter(!is.na(file)) |> 
  left_join(img_offsets, by = join_by(pos, t.frame)) |>
  
  # BUG HERE !!!!!
  mutate(xpos = xpos - y_offset_sum) |> # BUG HERE !!!!!
  mutate(ypos = ypos - x_offset_sum) |> # BUG HERE !!!!! 
  # BUG HERE !!!!!
  
  rcell2.magick::magickCell(images, normalize_images = T, return_single_imgs = T, annotation_params = NULL,
                            n.cells=nrow(d),
                            highlight_frames=t.bud,
                            ch = "TFP", boxSize=50)

# Preview.
pics |> 
  rcell2.magick::square_tile(nRow = 5) |> 
  # magick::image_append() |> 
  rcell2.magick::magickForKnitr()
```

## Process all

```{r}
w <- 100
s <- 500
s2 <- 0.75

off_drift_x <- 1
off_drift_y <- 1.5
```

```{r}
w <- 50
s <- NULL
s2 <- NULL

off_drift_x <- 0
off_drift_y <- 0
```

```{r}
process_one <- function(d){
    t.bud <- d$t.bud[1]
  
    xy <- d |> filter(t.bud == t.frame) |> with(c(xpos, ypos))
    
    img_paths <- images |> 
      semi_join(d, by = join_by(pos, t.frame)) |> 
      filter(channel == "TFP") |> 
      arrange(t.frame)
    
    # After budding.
    img_paths_post <- img_paths |> 
      filter(t.frame >= t.bud) |> 
      propagate_offsets(t.bud, xy, w, s, s2) |> 
      mutate(x_offset_sum = cumsum(x_offset-off_drift_x),
             y_offset_sum = cumsum(y_offset-off_drift_y))
    
    
    # Before budding.
    img_paths_pre <- img_paths |> 
      filter(t.frame <= t.bud) |> 
      arrange(-t.frame) |> 
      propagate_offsets(t.bud, xy, w, s, s2)|> 
      mutate(x_offset_sum = cumsum(x_offset-off_drift_x),
             y_offset_sum = cumsum(y_offset-off_drift_y))
    
    # Join results.
    img_offsets <- bind_rows(img_paths_pre, 
                             img_paths_post[-1,]) |> 
      arrange(t.frame) |> 
      select(pos, t.frame, x_offset, y_offset, x_offset_sum, y_offset_sum, t.ref)
    
    # Make images.
    pics <- d |> 
      left_join(img_offsets, by = join_by(pos, t.frame)) |> 
  
      # BUG HERE !!!!!
      mutate(xpos = xpos - y_offset_sum) |> # BUG HERE !!!!!
      mutate(ypos = ypos - x_offset_sum) |> # BUG HERE !!!!! 
      # BUG HERE !!!!!
      
      rcell2.magick::magickCell(images,
                                normalize_images = TRUE, return_single_imgs = TRUE, 
                                annotation_params = NULL, add_border = FALSE,
                                ch = "TFP", boxSize=w, n.cells = nrow(d))
    
    # Write images.    
    for(j in 1:nrow(d)){
      p <- file.path(out.dir, paste0("cell-", d$ucid[1], "-time-", d$t.frame[j], "-bud-", t.bud, ".tiff"))
      magick::image_write(image = pics[j], path = p, format = "tiff")
    }
    
    return(pics)
  }
```


```{r}
out.dir <- file.path("/tmp", "cells")
dir.create(out.dir, F, T)

d_list <- cdata_adj |> split(~ucid)
# d_list <- d_list[1:5]

# d <- d_list[[398]]
r <- d_list |> 
  lapply(function(d){
    tryCatch(process_one(d),
             error = function(e) cat("Failed to process cell", d$ucid[1], "\n"))
  })
```

```{r}
r[[1]] |> magick::image_info()
```


```{r}
failed_cells <- c(37,91,95,104,147,148,151,229,232,235,261,290,342,481,665,666,674,688,689)

cdata_adj |> 
  filter(t.frame == t.bud) |> 
  filter(!ucid %in% failed_cells) |> 
  select(ucid, t.frame) |> 
  mutate(x=w/2, y=w/2) |> 
  write.csv(file = "/tmp/cells_batch2.csv")
```

# Extras

## Drift problem

Conversation: <https://chatgpt.com/share/674f5516-bb78-800f-9038-e00152429327>

**Prompt**:

    I have a series of images over time, and would like to align the frames, that drift slightly in X and Y. I have tried to do cross-correlation as we already discussed, but i keep finding that the alignment "drifts" over frames. That is, if I find the relative offsets between adjacent frames, and then add them up to align the first image to the last, I find that an error accumulates, making the first image terribly unaligned to the last.

**Response**:
    
The "drift" problem you describe is common in iterative alignment techniques. This issue arises because small errors in estimating the alignment between consecutive frames accumulate over time, leading to significant misalignment between the first and last images. Here are some potential approaches to address this problem:
1. Use a Fixed Reference Frame

Instead of aligning each frame to its adjacent frame, align all frames directly to a single reference frame (e.g., the first frame or an average frame). This avoids error accumulation over time.
Steps:

    Compute the cross-correlation of each frame with the reference frame.
    Extract the offsets for each frame relative to the reference frame.
    Apply the offsets to align all frames to the reference frame.

2. Iterative Refinement with Global Optimization

You can reduce drift by globally optimizing the alignment across all frames. This can be achieved using techniques like:

    Mean Frame Alignment: Compute a "mean" frame by averaging all the frames (unaligned), then iteratively align each frame to this mean frame, updating the mean after each iteration until convergence.
    Circular Consistency Check: After aligning frames, compare the first and last frames. Adjust the offsets to ensure they align properly, distributing the error evenly across all frames.

3. Weighted Cross-Correlation

To avoid over-weighting noisy regions far from the point of interest, you can apply a Gaussian weighting centered on the expected alignment point. This makes the alignment less sensitive to peripheral features.
4. Rigid Registration

If your images contain objects with small shape variations, consider using a rigid registration technique:

    Use libraries such as SimpleITK in R (via Python integration if necessary).
    Align frames by optimizing transformations (translation, rotation, scaling).

5. Feature-Based Alignment

Rather than relying on cross-correlation, extract features (e.g., corners, edges) and match them between frames:

    Use packages like EBImage or integrate with Python libraries like OpenCV.
    Compute transformations (e.g., translation) to align features between frames.

6. Incorporate Drift Correction

A cumulative drift model can account for systematic drift:

    Estimate the drift vector across all frames using methods like least squares.
    Subtract the cumulative drift from each frame's offset.

7. Nonlinear Drift Models

If the drift is not linear, model it as a smooth curve:

    Use polynomial regression or spline fitting to model the drift across time.
    Correct offsets using the modeled drift.

## Optical flow

```{r}
library(reticulate)
```

```{r}
# reticulate::py_install(packages = c("numpy", "opencv-python", "matplotlib"))
# virtualenv_install("r-reticulate", packages = c("numpy", "opencv-python", "matplotlib"))
```

```{python}
import cv2
import numpy as np
import matplotlib.pyplot as plt
```

```{python}
path1 = "/tmp/cells/cell-1-time-4-bud-4.tiff"
path2 = "/tmp/cells/cell-1-time-5-bud-4.tiff"
# Load two consecutive frames as grayscale images
frame1 = cv2.imread(path1, cv2.IMREAD_GRAYSCALE)
frame2 = cv2.imread(path2, cv2.IMREAD_GRAYSCALE)
```

```{r}
c(py$path1, py$path2) |> 
  magick::image_read()
  # magick::image_append() |> 
  # rcell2.magick::magickForKnitr(.resize = 500)
```

```{python}
# Preprocessing step 1: Apply Gaussian Blur to reduce noise
frame1 = cv2.GaussianBlur(frame1, (5, 5), 0)
frame2 = cv2.GaussianBlur(frame2, (5, 5), 0)

# Preprocessing step 2: Equalize histogram to enhance contrast
# frame1 = cv2.equalizeHist(frame1)
# frame2 = cv2.equalizeHist(frame2)
```


> Smaller images require smaller analysis windows and fewer pyramid levels because there’s less spatial information to process.

```{python}
# Ensure frames are the same size
if frame1.shape != frame2.shape:
    raise ValueError("Frames must have the same dimensions")

# Compute dense optical flow using Farneback method
flow = cv2.calcOpticalFlowFarneback(
    frame1, frame2, None, 
    pyr_scale=0.5, levels=2, winsize=9, 
    iterations=4, poly_n=3, poly_sigma=1.1, flags=0
)
```


```{python}
# Visualize flow vectors
h, w = frame1.shape
g = 3
y, x = np.mgrid[0:h:g, 0:w:g].astype(np.int32)  # Grid for sampling
fx, fy = flow[y, x].T

# Overlay flow vectors on the first frame
plt.figure(figsize=(10, 10))
plt.imshow(frame1, cmap='gray')
scale_factor = 2  # Adjust this factor to amplify the vectors
plt.quiver(x, y, fx * scale_factor, fy * scale_factor, color='red', angles='xy', scale_units='xy', scale=1)
plt.title("Optical Flow Vectors")
plt.show()
```
